\chapter{Kiến thức nền tảng}
\section{Các định nghĩa và thuật ngữ}
Trong các công trình nghiên cứu về phân giải đồng tham chiếu, các tác giả thường sử dụng từ \emph{markable} để chỉ tới những từ/cụm từ cần được phân giải đồng chiếu, hoặc từ \emph{noun phrase} hay NP vì đa phần các công trình trước đây chỉ xem xét tới các danh từ/cụm danh từ. Một số tài liệu khác sử dụng từ \emph{mention} để chỉ tới những ``đề cập'' trong văn bản vì bản chất của phân giải đồng tham chiếu là xác định xem các từ/cụm từ có đề cập tới cùng một thực thể hay không. Để thuận tiện trong việc diễn đạt bằng tiếng Việt, chúng tôi sử dụng từ \emph{khái niệm} để chỉ tới những thực thể cần được phân giải đồng tham chiếu. Một lý do khác mà chúng tôi sử dụng từ này bắt nguồn từ việc Thách thức i2b2 năm 2011 gọi các tập tin chứa những thực thể đã được gán nhãn là ``concept files''.

Các khái niệm đa phần là danh từ hay cụm danh từ. Một khái niệm có thể được lồng trong khái niệm khác. Thông thường sự lồng nhau này xuất hiện ở những cụm danh từ mang ý nghĩa sở hữu, ví dụ cụm ``ngôi nhà của anh ta'' chứa hai khái niệm khác nhau là (ngôi nhà của anh ta) và (anh ta). Một số tài liệu gọi các khái niệm lồng nhau là \emph{khái niệm đầy đủ}. Một hệ thống phân giải đồng tham chiếu có xem xét đến sự lồng nhau này hay không phụ thuộc vào bước trích xuất và gán nhãn thực thể trước đó. Một số công trình nghiên cứu đề xuất các giải pháp phân giải riêng biệt cho các khái niệm lồng nhau, tuy nhiên phương pháp mà chúng tôi hiện thực ở đây không xem sự lồng nhau là một trường hợp đặc biệt.

Hai khái niệm được xem là \emph{đồng tham chiếu} nếu cả hai cùng chỉ về một thực thể trong thế giới thực, ví dụ ``thủ tướng Việt Nam'' và ``Nguyễn Tấn Dũng''. Một đặc điểm cần lưu ý của tính đồng tham chiếu là nó phụ thuộc vào ngữ cảnh và thời điểm mà các khái niệm được đề cập đến. Như ở ví dụ trên, hai khái niệm ``thủ tướng Việt Nam'' và ``Nguyễn Tấn Dũng'' chỉ đồng tham chiếu nếu thời điểm mà chúng được đề cập trong văn bản nằm trong khoảng thời gian mà ông Nguyễn Tấn Dũng đang là thủ tướng Việt Nam.

Có thể xem đồng tham chiếu là một mối quan hệ giữa hai hay nhiều khái niệm khi chúng cùng đề cập tới một thực thể. Dễ dàng nhận thấy đây là mối quan hệ tương đương vì nó có những tính chất sau:
\begin{itemize}
\item \emph{Tính phản xạ}: một khái niệm bất kì thì luôn đồng tham chiếu với chính nó.
\item \emph{Tính đối xứng}: nếu khái niệm $C_1$ đồng tham chiếu với $C_2$ thì $C_2$ cũng đồng tham chiếu với $C_1$.
\item \emph{Tính bắc cầu}: nếu khái niệm $C_1$ đồng tham chiếu với $C_2$, $C_2$ đồng tham chiếu với $C_3$ thì $C_1$ cũng đồng tham chiếu với $C_3$.
\end{itemize}

Một \emph{cặp khái niệm} gồm hai khái niệm có thể có hoặc không đồng tham chiếu với nhau. Đối với một cặp đồng tham chiếu, khái niệm đứng trước được gọi là \emph{tiền đề} (antecedent), khái niệm đứng sau được gọi là \emph{hồi chỉ} (anaphora). Những đặc trưng của một cặp khái niệm đa phần là những \emph{đặc trưng đồng thuận} (agreement feature), chúng mang giá trị là ``có'' khi cả hai khái niệm của cặp cùng đồng thuận về một đặc tính nào đó, ví dụ như sự đồng thuận về giới tính hay số lượng. Trong một văn bản, nhiều khái niệm có thể cùng tham chiếu tới cùng một thực thể, khi đó chúng tạo thành một chuỗi đồng tham chiếu.

\emph{Phân giải đồng tham chiếu} là công việc xác định những chuỗi đồng tham chiếu trong văn bản. Xuyên suốt này luận văn này, chúng tôi gọi các chuỗi đồng tham chiếu được phân giải bởi con người là các \emph{chuỗi kết quả}, các chuỗi được xuất ra bởi hệ thống phân giải đồng tham chiếu là các \emph{chuỗi hệ thống}.

\section{Các mô hình học máy phân giải đồng tham chiếu\label{coref-model}}
Phân giải đồng tham chiếu, một trong những tác vụ cơ bản của xử lý ngôn ngữ tự nhiên, là công việc xác định xem những khái niệm nào trong văn bản cùng chỉ đến một thực thể trong thế giới thực. Mặc dù nhiều phương pháp giải quyết đã được nghiên cứu phát triển từ những năm 60 của thế kỉ 20, các hệ thống dựa trên luật hay theo hướng tiếp cận heuristic trong thời gian này đòi hỏi nhiều kiến thức phức tạp và không thực sự hiệu quả (một trong những nền tảng của các hệ thống này là \emph{lý thuyết trung tâm} \cite{Grosz1983}).

Bắt đầu từ những năm 1990, khi các mô hình xác suất trở nên phổ biến vì tính hiệu quả của chúng, các phương pháp học máy phân giải đồng tham chiếu ra đời dần thay thế các phương pháp heuristic thủ công. Cùng với xu thế đó là sự xuất hiện của các tập dữ liệu được gán nhãn bắt nguồn từ hội nghị MUC-6 (1996) và MUC-7 (1997), các nghiên cứu về phân giải đồng tham chiếu dựa trên học máy càng được phát triển không chỉ cho các miền văn bản chung mà còn đi sâu vào các miền văn bản cụ thể (như Thách thức i2b2 năm 2011 về phân giải đồng tham chiếu cho bệnh án điện tử \cite{OzlemUzuner2012}).

Mặc dù tính bổ biến và sự hiệu quả của các phương pháp học máy có giám sát, sự khó khăn trong việc xây dựng các tập dữ liệu gán nhãn nhất là đối với các ngôn ngữ khác tiếng Anh đã làm động lực cho sự ra đời của các phương pháp học máy bán giám sát hoặc không giám sát. Ưu điểm của các phương pháp này là không cần đòi hỏi các tập dữ liệu đã gán nhãn hoặc chỉ cần gán nhãn một phần \cite{CardieWagstaff1999}.

Có ba mô hình học máy có giám sát được đề xuất để phân giải đồng tham chiếu: mô hình \emph{cặp khái niệm}, mô hình \emph{đề cập thực thể} và mô hình \emph{xếp hạng}. Mô hình cặp khái niệm ra đời đầu tiên và có ý tưởng đơn giản nhất, tuy nhiên cũng chính vì thế mà nó có một số nhược điểm khiến cho việc hiện thực không thực sự dễ dàng. Hai mô hình đề cập thực thể và xếp hạng được đề xuất sau đó nhằm khắc phục các nhược điểm của mô hình cặp khái niệm bằng cách đưa vào các ý tưởng thực tế hơn như \emph{đặc trưng ở mức cụm} \cite{Yang2004} hay huấn luyện một mô hình xếp hạng lựa chọn tiền đề \cite{Yang2003}.

Mặc dù có nhiều nhược điểm, mô hình cặp thực thể vẫn rất phổ biến nhờ ý tưởng đơn giản của nó, đặc biệt là trong các miền văn bản chuyển môn khi mà các đặc trưng chuyên sâu về một hay một vài lĩnh vực mang nhiều ý nghĩa hơn cho việc xác định tính đồng tham chiếu của các khái niệm. Điển hình là hệ thống có kết quả cao nhất trong Thử thách i2b2 năm 2011 sử dụng mô hình cặp khái niệm và tận dụng các thông tin về sự cập đến bệnh nhân, các kiến thức nền (Wikipedia, WordNet, v.v...) và các thông tin ngữ cảnh trong bệnh án \cite{YanXu2012}. Trong phần này chúng tôi chỉ trình bày cụ thể về mô hình cặp khái niệm vì đây cũng là mô hình được chúng tôi hiện thực trong hệ thống của mình.

\subsection*{Mô hình cặp khái niệm}
Đây là mô hình học máy phân giải đồng tham chiếu đầu tiên và được giới thiệu vào năm 1995 \cite{Aone&Bennett1995}. Ý tưởng chính của mô hình này là xác định tính đồng tham chiếu cho từng cặp hai khái niệm bất kì trong văn bản. Mặc dù mô hình cặp khái niệm phổ biến nhờ ý tưởng đơn giản của nó, tính bắc cầu của quan hệ đồng tham chiếu bị bỏ qua ở mô hình này vì trường hợp như sau có thể xảy ra: hai khái niệm $A$ và $B$ được xác định là đồng tham chiếu, $B$ và $C$ cũng được xác định là đồng tham chiếu trong khi $A$ và $C$ lại không được xác định là đồng tham chiếu. Điều này đòi hỏi phải có một cơ chế gom cụm các khái niệm và xây dựng các chuỗi sau khi đã xác định tính đồng tham chiếu cho các cặp hai khái niệm.

Một nhược điểm khác của mô hình này là để huấn luyện mô hình phân loại, ứng với mỗi cặp khái niệm hệ thống cần trích xuất các đặc trưng đại diện cho cặp, sau đó tổng hợp lại thành một tập dùng để huấn luyện. Mặt khác trong một văn bản, tổng số các cặp khái niệm có thể rất lớn trong khi số các cặp đồng tham chiếu lại rất nhỏ, như vậy nếu tất cả các cặp được rút trích đặc trưng sẽ dẫn đến tình trạng mất cân bằng lớp: các mẫu âm (các cặp không đồng tham chiếu) có số lượng lấn át các mẫu dương (các cặp đồng tham chiếu).

Một số công trình nghiên cứu đề xuất giải pháp cho vấn đề mất cân bằng lớp theo hướng tiếp cận heuristic. Chẳng hạn như chỉ xem xét sinh các mẫu dương từ các cặp đồng tham chiếu mà hai khái niệm gần kề nhau theo thứ tự xuất hiện, còn các mẫu âm được sinh theo quy tắc: với mỗi cặp đồng tham chiếu được sinh làm mẫu dương $(C_i,\,C_j)$, sinh các mẫu âm từ các cặp $(C_k,\,C_j)$ mà $i<k<j$ \cite{Soon2001}. Một chỉnh sửa nhỏ của cách này là loại bỏ đi các mẫu mà khái niệm đứng trước là một đại từ \cite{VincentNg2002a}. Hay một cách lọc mẫu khác được trình bày ở \cite{VincentNg2002b}: với mỗi hồi chỉ $C_j$ mà tiền xa nhất của nó là $C_i$, sinh tất cả các mẫu âm được tạo bởi $C_k$ và $C_j$ mà $i<k<j$. Ngoài ra, hệ thống ở \cite{VincentNg2002b} còn sử dụng luật quy nạp (rule induction) để lọc bỏ các mẫu dương khó làm ảnh hưởng đến việc huấn luyện.

Để xác định tính đồng tham chiếu cho hai khái niệm bất kì trong văn bản, hệ thống sử dụng mô hình cặp khái niệm trước tiên cần huấn luyện một mô hình phân loại. Một số giải thuật như cây quyết định hay luật quy nạp, v.v... được sử dụng ở thời kì đầu của ứng dụng học máy. Sau khi các mô hình thống kê trở nên phổ biến, một số giải thuật được sử dụng vào lĩnh vực này gồm có mô hình entropy cực đại \cite{Berger1996}, mạng neuron bầu cử \cite{Freund1999} và support vector machine. Các giải thuật học máy dựa trên mô hình thống kê có một đặc điểm lợi thế là chúng có thể xuất ra độ tin cậy đồng tham chiếu của các cặp khái niệm. 

Mô hình phân loại sau khi đã huấn luyện có thể được sử dụng để xác định tính đồng tham chiếu cho các cặp hai khái niệm. Tuy nhiên để có thể xây dựng các chuỗi đồng tham chiếu, cần thiết phải sử dụng một giải thuật gom cụm. Có hai giải thuật gom cụm được sử dụng phổ biến trong phân giải đồng tham chiếu:

\begin{enumerate}
\item \emph{Gom cụm gần nhất trước (closest-first clustering):}

Giải thuật này trước tiên chọn ra tiền đề ở gần nhất trước đó cho một hồi chỉ. Cụ thể với mỗi khái niệm $C_j$, giải thuật sử dụng mô hình phân loại đã được huấn luyện ở bước trước để xác định tính đồng tham chiếu cho từng cặp $(C_i,\,C_j)$ mà $i<j$. Sau khi gặp một cặp $(C_k,\,C_j)$ đầu tiên được xác định là đồng tham chiếu, giải thuật đưa cặp vào danh sách $L$. Sau khi đã chọn tiền cho toàn bộ hồi chỉ, từ danh sách $L$ các cặp có một chung khái niệm được gom lại với nhau thành từng cụm, mỗi cụm ứng với một chuỗi đồng tham chiếu \cite{Soon2001}.
\item \emph{Gom cụm tốt nhất trước (best-first clustering):}

Sự khác biệt của giải thuật này so với giải thuật trên là: thay vì chọn tiền đề ở gần nhất, giải thuật gom cụm tốt nhất trước lựa chọn tiền đề có độ tin cậy đồng tham chiếu cao nhất. Điều này có thể được thực hiện nhờ sử dụng các mô hình phân loại thống kê, điển hình là SVM. Theo các tác giả của giải thuật này, nhờ tận dụng được độ tin cậy đồng tham chiếu của mô hình phân loại, giải thuật gom cụm tốt nhất trước cho kết quả tốt hơn giải thuật gom cụm gần nhất trước \cite{VincentNg2002a}.
\end{enumerate}

\section{Support Vector Machine}
Trong lĩnh vực học máy, support vector machine (SVM) là mô hình học có giám với giải thuật huấn luyện có thể phân tích và nhận diện mẫu. Lần đầu tiên được giới thiệu bởi Vladimir N. Vapnik vào năm 1992, SVM là một trong những giải thuật học máy được sử dụng phổ biến nhất trong lĩnh vực học máy hiện đại, đa phần là bởi vì SVM thường tỏ ra hiệu quả hơn nhiều so với các giải thuật học máy khác khi được huấn luyện trên một tập dữ liệu vừa (SVM không làm việc tốt trên các tập dữ liệu quá lớn, vì giải thuật học của SVM có liên quan đến việc nghịch đảo các ma trận, một việc làm rất tốn kém về mặt tính toán). 

Tư tưởng cơ bản của SVM là cố gắng tìm kiếm một hoặc một tập các mặt siêu phẳng (hyperplane) trong một không gian có nhiều chiều để phân chia các điểm đại diện của tập dữ liệu ra hai hay nhiều phần, từ đó có thể thực hiện các tác vụ phân loại hay hồi quy. Một đặc điểm của SVM là giải thuật học của nó cho phép chúng ta phân biệt được giữa một mô hình phân loại tốt và một mô hình không tốt, ngay cả khi cả hai mô hình đều cho cùng một kết quả phân loại trên một tập dữ liệu.

Hình \ref{sep-eg} mô tả ba đường phân loại có thể cho một tập dữ liệu. Mặc dù cả ba đường đều phân loại các điểm thuộc các lớp khác nhau một cách chính xác, có thể cảm thấy rằng hình thứ ba cho một đường phân loại tốt hơn hai hình còn lại. Điều này có thể được giải thích là: khi sử dụng các đường ở Hình \ref{sep-eg} để phân loại cho các điểm dữ liệu mới, đường phân loại thứ ba cho xác suất các điểm này rơi vào phía phân lớp sai thấp hơn so với hai đường còn lại. Lý do là bởi vì khoảng cách từ đường phân loại thứ ba đến ba đến các điểm dữ liệu của hai lớp là lớn nhất và gần như là bằng nhau cho cả hai bên.

\begin{figure}[ht]
\centering
\begin{subfigure}[b]{0.32\textwidth}
\centering
\resizebox{\linewidth}{!}{
	\begin{tikzpicture}
		\draw[->] (-0.1,0) -- (4.1,0) node[below]{$x_1$};
		\draw[->] (0,-0.1) -- (0,4.1) node[left]{$x_2$};
		
		\draw (0.5,2.5) node[bpoint]{};
		\draw (1.5,2.85) node[bpoint]{};
		\draw (2.5,3.2) node[bpoint]{};
		\draw (0.7,3.7) node[bpoint]{};
		\draw (0.8,3.1) node[bpoint]{};
		\draw (1.3,3.8) node[bpoint]{};
		\draw (1.8,3.4) node[bpoint]{};
		
		\draw (1.2,1.5) node[wpoint]{};
		\draw (1.8,1.1) node[wpoint]{};
		\draw (2,1.8) node[wpoint]{};
		\draw (1.6,0.6) node[wpoint]{};
		\draw (2.3,0.8) node[wpoint]{};
		\draw (2.4,1.4) node[wpoint]{};
		\draw (2.8,1.7) node[wpoint]{};
		
		\draw (-0.5375,2.55) -- (3.975,1.6);
	\end{tikzpicture}
}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
\centering
\resizebox{\linewidth}{!}{
	\begin{tikzpicture}
		\draw[->] (-0.1,0) -- (4.1,0) node[below]{$x_1$};
		\draw[->] (0,-0.1) -- (0,4.1) node[left]{$x_2$};
		
		\draw (0.5,2.5) node[bpoint]{};
		\draw (1.5,2.85) node[bpoint]{};
		\draw (2.5,3.2) node[bpoint]{};
		\draw (0.7,3.7) node[bpoint]{};
		\draw (0.8,3.1) node[bpoint]{};
		\draw (1.3,3.8) node[bpoint]{};
		\draw (1.8,3.4) node[bpoint]{};
		
		\draw (1.2,1.5) node[wpoint]{};
		\draw (1.8,1.1) node[wpoint]{};
		\draw (2,1.8) node[wpoint]{};
		\draw (1.6,0.6) node[wpoint]{};
		\draw (2.3,0.8) node[wpoint]{};
		\draw (2.4,1.4) node[wpoint]{};
		\draw (2.8,1.7) node[wpoint]{};		
		
		\draw (-0.5,0) -- (3.5,4);
	\end{tikzpicture}
}
\end{subfigure}
\begin{subfigure}[b]{0.32\textwidth}
\centering
\resizebox{\linewidth}{!}{
	\begin{tikzpicture}
		\draw[->] (-0.1,0) -- (4.1,0) node[below]{$x_1$};
		\draw[->] (0,-0.1) -- (0,4.1) node[left]{$x_2$};
		
		\draw (0.5,2.5) node[bpoint]{};
		\draw (1.5,2.85) node[bpoint]{};
		\draw (2.5,3.2) node[bpoint]{};
		\draw (0.7,3.7) node[bpoint]{};
		\draw (0.8,3.1) node[bpoint]{};
		\draw (1.3,3.8) node[bpoint]{};
		\draw (1.8,3.4) node[bpoint]{};
		
		\draw (1.2,1.5) node[wpoint]{};
		\draw (1.8,1.1) node[wpoint]{};
		\draw (2,1.8) node[wpoint]{};
		\draw (1.6,0.6) node[wpoint]{};
		\draw (2.3,0.8) node[wpoint]{};
		\draw (2.4,1.4) node[wpoint]{};
		\draw (2.8,1.7) node[wpoint]{};	
		
		\draw (-0.5,1.5375) -- (4,3.1125);
	\end{tikzpicture}
}
\end{subfigure}
\caption{Ví dụ về các đường phân loại có thể cho một tập dữ liệu\label{sep-eg}}
\end{figure}

Như vậy mục đích của giải thuật học SVM chính tìm ra một đường phân loại tối ưu theo tiêu chí đã kể trên, tức là cực đại hóa khoảng cách của đường phân loại tới điểm gần nhất của hai lớp. Các điểm gần với đường phân loại nhất được gọi là các \emph{vector hỗ trợ} (support vector), các điểm này là quan trọng bởi vì chúng là những điểm dễ bị phân loại sai nhất trong quá trình học. Điều này dẫn đến một đặc điểm thú vị của giải thuật học SVM: sau khi huấn luyện, các điểm dữ liệu khác của tập huấn luyện có thể bỏ đi và chỉ cần giữ lại các vector hỗ trợ là đủ.

Giả sử tập dữ diệu huấn luyện được biểu diễn bằng một tập các điểm \[\mathcal{D}=\left\{(\vec{x}_i,y_i)\,|\,\vec{x}_i\in\mathbb{R}^p,\,y_i\in\{-1,1\}\right\}_{i=1}^{n}\] trong đó $y_i$ có thể là $-1$ hoặc $1$ mang ý nghĩa là lớp mà $\vec{x}_i$ thuộc vào, mỗi $\vec{x}_i$ là một vector có $p$ chiều. Một mặt siêu phẳng bất kì trong không gian $p$ chiều có thể được biểu diễn dưới dạng $\vec{w}\cdot\vec{x}+b=0$ với $\vec{w}\cdot\vec{x}$ là tích vô hướng của hai vector $\vec{w}$ và $\vec{x}$, tức $\vec{w}\cdot\vec{x}=\sum_{i=1}^{p}w_ix_i$. Trong đó $\vec{w}$ được gọi là vector pháp tuyến của mặt siêu phẳng $\vec{w}\cdot\vec{x}+b=0$, còn $\frac{b}{||\vec{w}||}$ là khoảng cách từ đường đến góc tọa độ.

Với mỗi đường phân loại bất kì, xét hai đường song song với nó và đi qua các điểm gần nhất của hai lớp (Hình \ref{optimal-sep}), gọi là hai đường biên. Để cho thuận tiện, gọi các điểm đen $\vec{x}^\bullet$ trên Hình \ref{optimal-sep} là các điểm thuộc vào lớp 1, còn các điểm trắng $\vec{x}^\circ$ là các điểm thuộc vào lớp $-1$. Như vậy nếu đường phân loại có dạng $\vec{w}\cdot\vec{x}+b=0$ thì các điểm đen và trắng được phân loại theo tiêu chí $\vec{w}\cdot\vec{x}^\bullet+b\geq1$ và $\vec{w}\cdot\vec{x}^\circ+b\leq-1$. Dễ dàng suy ra phương trình của đường biên đen là $\vec{w}\cdot\vec{x}+b=1$ và của đường biên trắng là $\vec{w}\cdot\vec{x}+b=-1$, từ đó tính được khoảng cách của hai đường biên là $\frac{2}{||\vec{w}||}$.

Như đã nói ở trên, các điểm đen có phân lớp $y=1$, tiêu chí phân loại các điểm này là $\vec{w}\cdot\vec{x}^\bullet+b\geq1$. Trong khi đó các điểm trắng có phân lớp $y=-1$ được phân loại theo tiêu chí $\vec{w}\cdot\vec{x}^\circ+b\leq-1$. Các tiêu chí này có thể được viết lại một cách đơn giản là: $y(\vec{w}\cdot\vec{x}+b)\geq1$. Mặt khác, để cực đại hóa khoảng cách của hai đường biên, tức cực đại hóa $\frac{2}{||\vec{w}||}$, thì $||\vec{w}||$ phải đạt cực tiểu. Như vậy mục đích cuối cùng của giải thuật học SVM là cực tiểu hóa $||\vec{w}||$ với điều kiện $y_i(\vec{w}\cdot\vec{x}_i+b)\geq1$ cho mọi $i=1,\dots,n$.

\begin{figure}[ht]
\centering
\scalebox{1.5}{
	\begin{tikzpicture}[font=\tiny]
		\draw[->] (-0.1, 0) -- (4.1, 0) node[below]{$x_1$};
		\draw[->] (0, -0.1) -- (0, 4.1) node[left]{$x_2$};
			
		\draw[thick,gray!60] (0.5, 2.5) node[bpoint]{};
		\draw[thick,gray!60] (1.5, 2.85) node[bpoint]{};
		\draw[thick,gray!60] (2.5, 3.2) node[bpoint]{};
		\draw (0.7, 3.7) node[bpoint]{};
		\draw (0.8, 3.1) node[bpoint]{};
		\draw (1.3, 3.8) node[bpoint]{};
		\draw (1.8, 3.4) node[bpoint]{};
		
		\draw[thick] (1.2, 1.5) node[wpoint]{};
		\draw (1.8, 1.1) node[wpoint]{};
		\draw[thick] (2, 1.8) node[wpoint]{};
		\draw (1.6, 0.6) node[wpoint]{};
		\draw (2.3, 0.8) node[wpoint]{};
		\draw (2.4, 1.4) node[wpoint]{};
		\draw (2.8, 1.7) node[wpoint]{};	
			
		\draw (-0.55,1.52) -- (3.809,3.0457) node[pos=0.8,sloped,above,outer sep=0,inner sep=0.5mm]{$\vec{w}\cdot\vec{x}+b=0$};
		
		\draw[dashed] (-0.68,2.087) -- (3.618,3.5913) node[pos=1,sloped,above,outer sep=0,inner sep=0.5mm]{$\vec{w}\cdot\vec{x}+b=1$};
		\draw[dashed] (-0.3,0.9825) -- (4.004,2.4889) node[pos=0.8,sloped,above,outer sep=0,inner sep=0.5mm]{$\vec{w}\cdot\vec{x}+b=-1$};
		
		\draw[<->] (4.0707,2.5122) -- (3.6859,3.6147) node[midway,above,sloped]{$\frac{2}{||\vec{w}||}$};
		\draw[<->] (-0.0668,-0.0234) -- (-0.6001,1.5022) node[midway,below,sloped]{$\frac{b}{||\vec{w}||}$};
	\end{tikzpicture}
}
\caption{Tối ưu hóa khoảng cách của đường phân loại\label{optimal-sep}}
\end{figure}

\subsection*{Đường biên mềm}
Như đã đề cập ở trên, bài toán huấn luyện SVM mang bản chất là bài toán tối ưu tuyến tính với hàm mục tiêu (objective function)
\begin{equation}\label{svm-hard-obj-func}
L(\vec{w})=\vec{w}\cdot\vec{w}
\end{equation}
và các ràng buộc
\begin{equation}\label{svm-hard-constraints}
y_i(\vec{w}\cdot\vec{x}_i+b)\geq1\,,\forall i=1,\dots,n
\end{equation}

Tuy nhiên nhiều bài toán phân loại sẽ không giải quyết được với những điều kiện chặt như vậy, tức tìm kiếm một mặt siêu phẳng có thể phân chia các điểm dữ liệu của hai lớp ra hai bên một cách hoàn hảo. Một ví dụ điển hình là khi tập dữ liệu xuất hiện nhiễu (noise).

Năm 1995, Corinna Cortes và Vladimir N. Vapnik đề xuất chỉnh sửa ý tưởng học SVM chặt để cho phép phân loại sai một số điểm dữ liệu, gọi là phương pháp \emph{đường biên mềm} (soft margin). Nếu không thể tìm ra một mặt siêu phẳng hoàn hảo, phương pháp đường biên mềm sẽ cố gắng tìm một mặt siêu phẳng nào đó có thể phân chia các điểm dữ liệu một cách càng gọn càng tốt, trong khi vẫn có thể duy trì khoảng cách cực đại từ nó đến các điểm phân loại đúng gần nhất. Để làm được điều đó, phương pháp này giới thiệu một biến mới $e_i$ vào trong ràng buộc ở (\ref{svm-hard-constraints}), gọi là \emph{biến lỏng} (slack variable):
\begin{equation}
y_i(\vec{w}\cdot\vec{x}_i+b)\geq1-e_i\,,\forall i=i,\dots,n
\end{equation}

Với chỉnh sửa như trên, hàm mục tiêu (\ref{svm-hard-obj-func}) trở thành:
\begin{equation}\label{svm-soft-obj-func}
L(\vec{w},\vec{e})=\vec{w}\cdot\vec{w}+C\sum_{i=1}^{n}e_i
\end{equation}
trong đó, $C$ là tham số đánh đổi (trade-off) giữa khoảng cách biên lớn và số điểm phân loại sai nhỏ. Đa phần các giải thuật SVM được hiện thực hiện nay đều sử dụng phương pháp đường biên mềm vì tính linh hoạt của nó. Để giải quyết bài toán tối ưu cho phương pháp đường biên mềm, khi mà hàm mục tiêu là một hàm hai biến, một kĩ thuật gọi là \emph{quy hoạch toàn phương} (quadratic programming) được giới thiệu để loại bỏ $\vec{w}$ ra khỏi phương trình (\ref{svm-soft-obj-func}) và biến đổi nó trở thành:
\begin{equation}\label{svm-soft-obj-func-modified}
L(\vec{a})=\sum_{i=1}^{n}a_i-\frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{n}a_ia_jt_it_j\vec{x}_i\cdot\vec{x}_j
\end{equation}
với các ràng buộc $0\leq a\leq C$ và $\sum_{i=1}^{n}a_i\vec{x}_k=0$.

\subsection*{Kĩ thuật kernel}
Trong nhiều trường hợp, các điểm đại diện của tập dữ liệu không thể nào được phân cách bằng một mặt siêu phẳng trong chiều không gian gốc của nó. Khi này, một kĩ thuật biến đổi dữ liệu được áp dụng để nâng số chiều của không gian dữ liệu lên, với mục đích là tìm kiếm mặt phân loại siêu phẳng tối ưu trong các chiều không gian mới. Hình \ref{kernel-trick} mô tả một tập dữ liệu ở hai chiều được biến đổi sang một không gian ba chiều. Có thể dễ dàng nhận thấy, trong không gian hai chiều, các điểm dữ liệu của hai lớp không thể được phân cách bằng một đường thẳng. Tuy nhiên sau khi biến đổi dữ liệu để số chiều tăng lên, chúng dễ dàng được phân cách bởi một mặt phẳng.

\begin{figure}[ht]
\begin{subfigure}[b]{0.49\textwidth}
\centering
\begin{tikzpicture}
	\draw[->] (-2.5, 0) -- (2.5, 0) node[below]{$x_1$};
	\draw[->] (0, -2.5) -- (0, 2.5) node[left]{$x_2$};
	
	\draw[dashed] (0,0) node[ellipse,draw,minimum width=3cm,minimum height=2cm]{};
	
	\draw (0.1,0.15) node[swpoint]{};
	\draw (0.5,0.65) node[swpoint]{};
	\draw (1,0.25) node[swpoint]{};
	\draw (0.9,-0.45) node[swpoint]{};
	\draw (0.3,-0.25) node[swpoint]{};
	\draw (-0.45,-0.55) node[swpoint]{};
	\draw (-0.45,0.5) node[swpoint]{};
	\draw (-1.2,0.15) node[swpoint]{};
	
	\draw (0.6,1.5) node[sbpoint]{};
	\draw (1.7,0.6875) node[sbpoint]{};
	\draw (1.803,1.845) node[sbpoint]{};
	\draw (1.1,1.1) node[sbpoint]{};
	\draw (0.9,1.92) node[sbpoint]{};
	
	\draw (1.5,-0.7) node[sbpoint]{};
	\draw (2.2,-0.9) node[sbpoint]{};
	\draw (2,-1.85) node[sbpoint]{};
	\draw (1.1,-1.3) node[sbpoint]{};
	\draw (0.7,-2) node[sbpoint]{};
	
	\draw (-0.5,-1.85) node[sbpoint]{};
	\draw (-1.35,-1.9) node[sbpoint]{};
	\draw (-0.7,-1.2) node[sbpoint]{};
	\draw (-1.4,-0.8) node[sbpoint]{};
	\draw (-2,-0.5) node[sbpoint]{};
	
	\draw (-2.2,0.8) node[sbpoint]{};
	\draw (-1.45,0.7) node[sbpoint]{};
	\draw (-1,1.4) node[sbpoint]{};
	\draw (-0.9,2.2) node[sbpoint]{};
	\draw (-2,1.9) node[sbpoint]{};
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}[b]{0.49\textwidth}
\centering
\begin{tikzpicture}
	\draw[-,dashed] (0,0) -- (1.5,0);
	\draw[->] (1.5,0) -- (3.8,0) node[below]{$z_1$};
	\draw[-,dashed] (0,0) -- (0,2.5);
	\draw[->] (0,2.5) -- (0,3.8) node[left]{$z_3$};
	\draw[dashed] (0,0) -- (0,0,0.8);
	\draw[->] (0,0,0.8) -- (0,0,3.8) node[below right]{$z_2$};
	
	\draw (1.5,0) -- (0,2.5);
	\draw (1.5,0) -- (1.5,0,3.5) -- (0,2.5,3.5) -- (0,2.5);
	
	\draw (0.3,1.75) node[swpoint]{};
	\draw (0.35,1.4) node[swpoint]{};
	\draw (0.7,1) node[swpoint]{};
	\draw (0.5,0.7) node[swpoint]{};
	\draw (0.8,0.6) node[swpoint]{};
	\draw (0.7,0.35) node[swpoint]{};
	\draw (0.2,0.35) node[swpoint]{};
	\draw (1.1,0.2) node[swpoint]{};
	
	\draw (0.4,2.2) node[sbpoint]{};
	\draw (0.8,2.55) node[sbpoint]{};
	\draw (0.75,3.2) node[sbpoint]{};
	\draw (1,1.85) node[sbpoint]{};
	\draw (1.15,1.2) node[sbpoint]{};
	\draw (1.45,0.7) node[sbpoint]{};
	\draw (2,0.5) node[sbpoint]{};
	\draw (1.3,2.9) node[sbpoint]{};
	\draw (1.55,2) node[sbpoint]{};
	\draw (1.95,2.45) node[sbpoint]{};
	\draw (2.1,3.3) node[sbpoint]{};
	\draw (2.45,2.25) node[sbpoint]{};
	\draw (2.75,1.35) node[sbpoint]{};
\end{tikzpicture}
\end{subfigure}
\caption{Minh họa kĩ thuật kernel giúp biến đổi không gian dữ liệu\label{kernel-trick}}
\end{figure}

Để giúp SVM có thể tìm kiếm các mặt siêu phẳng trong các chiều không gian cao hơn, một kĩ thuật được giới thiệu có tên là kernel giúp làm tăng số chiều của dữ liệu mà không làm mất đi bản chất của nó. Cơ sở của kĩ thuật này là khi thay $\vec{x}$ trong phương trình (\ref{svm-soft-obj-func-modified}) bằng một vector $\Phi(\vec{x})$ có nhiều số chiều hơn được biến đổi từ $\vec{x}$, tích $\Phi(\vec{x}_j)\cdot\Phi(\vec{x}_j)$ trong phương trình sau một số phép biến đổi sẽ trở thành một hàm kernel đối với $\vec{x}_i$ và $\vec{x}_j$, $\Kernel(\vec{x}_i,\vec{x}_j)$. Vì số chiều của $\Phi(\vec{x})$ có thể là rất lớn, phép biến đổi kernel giúp cho giải thuật có tính khả thi về mặt tính toán. Cụ thể là thay vì sử dụng trực tiếp các $\Phi(\vec{x})$, ta có thể thay thế tích $\vec{x}_i\cdot\vec{x}_j$ bằng ngay chính hàm kernel $\Kernel(\vec{x}_i,\vec{x}_j)$. Sau đây là một số hàm kernel thông dụng:

\begin{itemize}
\item hàm đa thức (polynomial) biến đổi số chiều lên một mức độ $s$ nào đó:
\[\Kernel(\vec{x},\vec{y})=(1+\vec{x}\cdot\vec{y})^s\]
\item hàm xichma (sigmoid function) với tham số $\kappa$ và $\delta$:
\[\Kernel(\vec{x},\vec{y})=\tanh(\kappa \vec{x}\cdot \vec{y}-\delta)\]
\item một số dạng hàm bán kính cơ sở (radial basis function) như:
\begin{itemize}
\item kernel Gauss: $\Kernel(\vec{x},\vec{y})=\exp\left(-\dfrac{||\vec{x}-\vec{y}||^2}{2\sigma^2}\right)$
\item kernel mũ: $\Kernel(\vec{x},\vec{y})=\exp\left(-\dfrac{||\vec{x}-\vec{y}||}{2\sigma^2}\right)$
\item kernel Laplace: $\Kernel(\vec{x},\vec{y})=\exp\left(-\dfrac{||\vec{x}-\vec{y}||}{\sigma}\right)$
\end{itemize}
\end{itemize}

Việc tìm kiếm các bộ tham số tốt nhất cho hàm kernel có thể được thực hiện bằng nhiều cách, trong đó cách tìm kiếm lưới (grid search) được cho là đơn giản nhất và có thể song song hóa được. Ví dụ để huấn luyện một mô hình SVM với kernel Gauss, có hai tham số cần được xác định là $C$ (tham số đánh đổi ở phương trình (\ref{svm-soft-obj-func})) và $\gamma=\frac{1}{2\sigma^2}$ là tham số của kernel. Một cách tìm kiếm lưới thường được thực hiện là duyệt toàn bộ các cặp $(C,\gamma)$ với $C\in\{2^{-5},2^{-3},\dots,2^{13},2^{15}\}$ và $\gamma\in\{2^{-15},2^{-13},\dots,2^1,2^3\}$ để tìm ra bộ $(C,\gamma)$ tối ưu nhất dựa trên một phép kiểm chứng nào đó, ví dụ phép kiểm chứng chéo $k$ mẫu ($k$-fold cross validation).

\subsection*{Mô hình SVM mở rộng}
Mô hình SVM về bản chất chỉ phân loại được cho hai lớp, tuy nhiên trong thực tế có nhiều bài toán mà dữ liệu được phân vào nhiều hơn hai lớp. Để giải quyết các bài toán dạng này, một số phương pháp được đề xuất để mở rộng SVM cho các bài toán phân loại nhiều lớp. Tư tưởng cơ bản của các phương pháp này là thay vì chỉ huấn luyện một mô hình, giải thuật học mở rộng huấn luyện nhiều mô hình SVM phân loại hai lớp, sau đó sử dụng biểu quyết (vote) để quyết định phân lớp của dữ liệu. Có hai phương pháp thông dụng để mở rộng SVM cho phân loại nhiều lớp:
\begin{enumerate}
\item \emph{Một đấu với tất cả (one-against-all):}

Huấn luyện tất cả $n$ mô hình ứng với $n$ lớp. Mô hình thứ $i$ được huấn luyện để phân loại dữ liệu vào lớp $i$ hoặc lớp khác $i$. Như vậy ứng với $n$ mô hình là $n$ phương trình mặt siêu phẳng:
\[
\begin{matrix}
\vec{w}_1\cdot\vec{x}+b_1\\
\vdots\\
\vec{w}_n\cdot\vec{x}+b_n
\end{matrix}
\]

Sau khi huấn luyện, với mỗi điểm dữ liệu cần phân loại $\vec{x}^*$, giải thuật lựa chọn phân lớp $k$ sao cho $|\vec{w}_k\cdot\vec{x}^*+b_k|$ có giá trị lớn nhất.
\item \emph{Một đấu với một (one-against-one):}

Huấn luyện $m$ mô hình cho bài toán có $n$ lớp, mỗi mô hình có nhiệm vụ phân loại dữ liệu vào hai lớp bất kì trong $n$, tức $m$ chính là tổ hợp chập 2 của $n$: $m=\frac{n(n-1)}{2}$:\[(1,2),(1,3),\dots,(1,n),(2,3),(2,4),\dots,(2,n),\dots,(n-1,n)\]

Sau khi huấn luyện, với mỗi điểm dữ liệu cần phân loại $\vec{x}^*$, giải thuật lựa chọn phân lớp mà $\vec{x}^*$ được phần lớn $m$ mô hình phân loại vào.
\end{enumerate}

\section{Các công cụ hỗ trợ rút trích đặc trưng} \label{tools}
Vì đầu vào của hệ thống phân giải đồng tham chiếu là các văn bản thô và danh sách các khái niệm, chúng cần được rút trích đặc trưng và mã hóa thành dạng số để có thể đưa vào huấn luyện SVM. Để thuận tiện, chúng tôi sử dụng một số công cụ để xử lý chung về ngôn ngữ tự nhiên hay hỗ trợ rút trích một số thông tin ngữ nghĩa như thời gian hoặc các thông tin từ vựng liên quan đến chuyên ngành y tế. Sau đây chúng tôi trình bày các công cụ được sử dụng và mục đích cụ thể của chúng.

\subsection*{OpenNLP}
Thư viện Apache OpenNLP bao gồm các công cụ dựa trên học máy dùng để xử lý, phân tích các chuỗi văn bản được viết dưới dạng ngôn ngữ tự nhiên. OpenNLP hỗ trợ rất nhiều tác vụ cơ bản trong xử lý ngôn ngữ tự nhiên, trong số đó các tác vụ tách từ (tokenize), xác định từ loại (part-of-speech tagging), phân định cụm từ (chunking) và xác định danh từ trung tâm (head nouns) được chúng tôi sử dụng để hỗ trợ quá trình rút trích đặc trưng trong hệ thống. 

Trong việc phân tích từ vựng (lexical analysis), tác vụ tách từ là tác vụ chia nhỏ câu văn thành các thành phần nhỏ hơn như từ, cụm từ, ký hiệu, hoặc các yếu tố có ý nghĩa khác được gọi chung là token. Ví dụ câu văn \texttt{"The female patient is 65 years old ."} sau khi được phân giải sẽ gồm các token là \texttt{"The"}, \texttt{"Female"}, \texttt{"patient"}, \texttt{"is"}, \texttt{"65"}, \texttt{"years"}, \texttt{"old"} và \texttt{"."}. Ở đây các dấu câu hoặc các ký tự đặc biệt cũng được xem như là token. Trong hệ thống của chúng tôi, tác vụ tách từ được sử dụng như một tác vụ hỗ trợ cho các tiến trình khác như xác định từ loại hay phân định cụm từ.

Phân định cụm từ là quá trình phân tích câu văn thành các cụm động từ, cụm giới từ, cụm danh từ, cụm trạng từ, ... cấu thành nên câu văn đó. Ví dụ trong câu văn ``The patient is a 47 years old male'' được phân đoạn thành ba cụm: cụm danh từ ``The patient'', cụm động từ ``is'', cụm danh từ ``a 47 years old male''. Vai trò cũng như loại của cụm từ được định nghĩa trong tập nhãn Penn TreeBank \cite{Santorini1990}. Các cụm từ được mô tả theo định dạng IBO giúp xác định vị trí của từ  đang xét trong cụm từ. B mang ý nghĩa từ đang xét nằm đầu cụm từ, I mang ý nghĩa từ đang xét nằm trong cụm từ nhưng không phải là từ đầu tiên, O mang ý nghĩa từ đang xét nằm ngoài cụm từ. Ví dụ cụm danh từ ``a 47 years old'' được cấu thành từ ``a|B'', ``47|I'', ``years|I'', ``old|I''.

Xác định từ loại là tác vụ phân loại các từ dựa vào vai trò ngữ pháp của chúng trong câu. Danh sách các vai trò ngữ pháp trong tiếng Anh được định nghĩa sẵn dựa theo dự án Penn TreeBank \cite{Santorini1990}. Bảng \ref{tab:POSTag} miêu tả một số nhãn từ loại thông dụng. Tác vụ xác định từ loại được thư viện OpenNLP hỗ trợ bằng phương thức nhận vào một mảng các Token và trả về một mảng các vai trò ngữ pháp tương ứng với các token đó. Ví dụ câu văn \texttt{"They refuse to permit us"} được tách từ thành \texttt{[They, refuse, to, permit, us]} và được xác định từ loại như sau \texttt{[They/PRP, refuse/VBP, to/TO, permit/VB]}.

Trong ngôn ngữ học, trung tâm của một cụm từ là từ giúp xác định vai trò ngữ pháp cụm từ đó. Ví dụ từ trung tâm của cụm danh từ \texttt{"boiling hot water"} là danh từ \texttt{"water"}. Thư viện OpenNLP hỗ trợ tác vụ xác định danh từ trung tâm bằng phương thức nhận vào một cụm từ theo định dạng IBO và trả về từ trung tâm của cụm từ đó.

\begin{table}[ht]
\centering\ra{1.2}
\caption{Các nhãn từ loại thông dụng \label{tab:POSTag}}
\footnotesize\sffamily

\begin{tabularx}{0.8\textwidth}{@{}l *5{>{\arraybackslash}X}@{}}
\toprule 
\textbf{Nhãn} & \textbf{Ý nghĩa} & \textbf{Ví dụ}\\
\midrule
CC & Liên từ (conjunction) & and, or, but\\
DT & Mạo từ xác định (determiner) & the, a, an, these\\
JJ & Tính từ (adjective) & nice, easy \\
NN & Danh từ số ít (singular noun) & tiger, chair \\
NNS & Danh từ số nhiều (plural noun) & tigers, chairs \\
PRP & Đại từ chỉ người (personal pronoun) & me, you, I \\
RB & Phó từ (adverb) & extremely, loudly \\
VB & Động từ nguyên mẫu & think  \\
VBZ & Động từ ngôi thứ ba & thinks \\
VBD & Động từ quá khứ & thought \\
WDT & Nghi vấn từ xác định & which, whatever, whichever\\
WP & Nghi vấn từ chỉ người & what, who, whom \\
WRB & Nghi vấn từ chỉ phó từ & where, when \\
WP\$ & Nghi vấn từ sở hữu & whose, whosever \\
\bottomrule
\end{tabularx}
\end{table}

\subsection*{MetaMap}
UMLS là kho từ vựng y sinh do Thư viện Y học Quốc gia Hoa Kì tiến hành xây dựng từ năm 1986 nhằm phục vụ cho nhu cầu tra cứu thông tin đã được chuẩn hóa về các loại bệnh, thuốc, nguyên nhân hoặc các thuật ngữ trong y tế. Bộ từ điển UMLS tích hợp hơn 2 triệu tên gọi cho khoảng 900.000 khái niệm y sinh và khoảng 12 triệu tên gọi cho quan hệ giữa các khái niệm này \cite{Olivier2004}. Hiện nay, bộ từ điển UMLS vẫn đang được tiếp tục cập nhật và cho phép sử dụng miễn phí phục vụ mục đích nghiên cứu khoa học.

\begin{figure}[h]
\centering
\resizebox{\textwidth}{!}{
\begin{tikzpicture}[%
	>=angle 60,
	start chain=going right,
	node distance=3cm and 0.8cm,
	every join/.style={->, draw},
	font=\scriptsize\sffamily]
	\tikzset{
		bproc/.style = {draw, rectangle, on chain, on grid, text width=2.8cm, minimum height=1.4cm, inner sep=0.5mm, align=center}
	};
	
	\node[bproc](tkn){Nhận diện câu văn và tách từ};
	\node[bproc,join](pos){Đánh dấu vai trò ngữ pháp (POS)};
	\node[bproc,join](lkw){Tra cứu từ vựng};
	\node[bproc,join](sta){Phân tích cú pháp câu};
	
	\node[bproc,below=of tkn](vgp){Bộ sinh các biến thể từ cụm từ cho trước};
	\node[bproc,join](cdd){Nhận dạng các ứng cử viên (candidate)};
	\node[bproc,join](map){Xây dựng các ánh xạ};
	\node[bproc,join](ars){Phân giải nhập nhằng};
	\node[cylinder, minimum width=1.3cm, minimum height=1.3cm, draw, shape border rotate=90, below=1cm of map,shape aspect=.4](umls){UMLS};
	
	\draw[->] (sta.south) -- ++(down:0.8cm) -| (vgp.north);	
	\draw[dashed] ($(tkn.north west)+(-0.4,0.4)$) rectangle ($(sta.south east)+(0.4,-0.4)$);
	\coordinate[left=2.2cm of tkn.west](left-tkn);
	\draw[->] (left-tkn) -- (tkn) node[above,midway]{dữ liệu đầu vào};
	\draw[->] (umls.top) -- (map);
\end{tikzpicture}
}
\caption{Kiến trúc tổng quát của MetaMap\label{metamapstructure}}
\end{figure}

MetaMap là công cụ hỗ trợ nhận dạng các khái niệm trong bộ từ điển UMLS từ các văn bản y sinh. Đầu vào của MetaMap là văn bản thuần không có cấu trúc, từ văn bản này MetaMap xuất ra các chuỗi định dạng XML hoặc định dạng gần gũi với con người chứa các khái niệm trong từ điển UMLS nhận dạng được. Các thông tin từ UMLS rút trích được bao gồm: mã khái niệm trong bộ từ điển UMLS, các từ đồng nghĩa và lớp ngữ nghĩa của khái niệm trong UMLS. Hình \ref{metamapstructure} miêu tả kiến trúc tổng quát của MetaMap. Quá trình xử lý dữ liệu của MetaMap có thể được tóm tắt qua hai bước. Bước đầu, dữ liệu dạng văn bản được áp dụng các tác vụ xử lý ngôn ngữ tự nhiên cơ bản như: tách câu, tách từ, xác định từ loại, tra cứu từ vựng và phân tích cú pháp. Kết quả của bước đầu tiên là các cụm từ (phrase) được xác định từ văn bản đầu vào. Ở bước thứ hai, MetaMap tiến hành sinh các biến thể (variant) cho các cụm từ đã tìm được, xác định ứng cử viên (candidate) từ các khái niệm trong UMLS khớp với các biến thể được sinh ra và tính độ tin cậy cho các ứng cử viên đó. Đầu ra của bước thứ hai là các cụm từ được phân giải từ bước đầu, kèm theo các ứng cử viên trong bộ từ điển UMLS ứng với mỗi cụm. Trong phạm vi luận án, chúng tôi sử dụng tên khái niệm và lớp ngữ nghĩa của khái niệm từ đầu ra của MetaMap cho quá trình rút trích đặc trưng.

Ví dụ khi đưa câu văn \texttt{"The patient has been HIV positive for two years"} vào hệ thống MetaMap để phân tích thì ở kết quả của bước một, câu văn được phân tách thành ba cụm từ \texttt{"The patient}, \texttt{"has been"} và \texttt{"HIV positive for two years"}. Sau đó MetaMap thực hiện bước thứ hai lên các cụm từ này để cho ra kết quả cuối cùng, chúng được trình bày trên Hình \ref{metamapoutput}. Sau đây là các giải thích cho các kết quả này:

\begin{itemize}
\item Dòng 1, 2 và 3 mô tả cụm từ \texttt{"The patient"} với một ứng cử viên có độ tin cậy 1000 ứng với khái niệm \texttt{"patient"} mang mã số khái niệm là C0030705. Khái niệm \texttt{"patient"} thuộc lớp ngữ nghĩa bệnh nhân hoặc nhóm khuyết tật (Patient or Disabled Group) trong bộ từ điển UMLS.
\item Dòng 5 và 7 lần lượt mô tả các từ \texttt{"has"} và \texttt{"been"} không được tìm thấy bất kì ứng cử viên nào.
\item Các dòng từ 9 trở đi mô tả kết quả cho cụm từ \texttt{"HIV positive for two years"} với một ứng cử viên có độ tin cậy 875. Ứng cử viên này bao gồm ba khái niệm là \texttt{"positive for HIV"} mang mã số là C0019699, \texttt{"two"} mang mã số là C0205448 và \texttt{"years"} mang mã số là C0439234. 
\end{itemize}

\begin{figure}[ht]
\centering
\lstset{
	keywords={},
	tabsize=3,
	%frame=lines,
	frame=single,
	xleftmargin=20pt,
	framexleftmargin=15pt,
	numbers=left,
	numberstyle=\tiny,
	numbersep=5pt,
	breaklines=true,
	showstringspaces=false,
	columns=fullflexible,
	basicstyle=\footnotesize\ttfamily}
\lstinputlisting{sample_code/metamap_output.txt}
\caption{Mẫu kết quả của công cụ MetaMap\label{metamapoutput}}
\end{figure}

\subsection*{cTakes và các công cụ dựa trên cTakes}
Apache cTakes (clinical Text Analysis and Knowledge Extraction System) là hệ thống xử lý ngôn ngữ tự nhiên giúp rút trích thông tin từ các bệnh án điện tử dưới dạng văn bản thuần không có cấu trúc. Hệ thống cTakes có khả năng nhận diện các thực thể trong y tế như tên thuốc, các bất thường sức khỏe hay các triệu chứng/rối loạn, v.v... Hệ thống cTakes bao gồm nhiều bộ phận nhỏ như phát hiện câu văn, đánh dấu vai trò ngữ pháp, tra cứu dựa trên các bộ từ điển y tế hay chuẩn hóa thông tin y tế, v.v... Mỗi bộ phận của cTakes được huấn luyện chuyên biệt cho lĩnh vực y tế, các thông tin rút trích có thể được sử dụng làm đầu vào cho các hệ thống hỗ trợ ra quyết định y tế hoặc dùng để nghiên cứu.

cTakes được xây dựng dựa trên framework UIMA cho phép ứng dụng được cấu tách thành từ các hệ thống con (subsystem). Mỗi hệ thống con hiện thực một nhiệm vụ nhất định và được cung cấp một tập tin XML đóng vai trò là siêu dữ liệu mô tả hệ thống con đó. Hình \ref{ctakesdesc} trình bày tập tin XML mô tả hệ thống xác định từ loại của cTakes, đầu vào của hệ thống này là đường dẫn tới tập tin mô hình đã được huấn luyện cho việc xác định từ loại. Ngoài ra framework UIMA còn hỗ trợ cTakes gói các hệ thống con lại như một mạng lưới các dịch vụ, trong đó các hệ thống con của cùng mạng lưới có thể giao tiếp với nhau thông quá các miêu tả trong tập tin XML, tương tự như mô hình đường ống (pipeline). Trong phạm vi luận án, chúng tôi sử dụng công cụ MedEx \cite{HuaXu2009} và MedTime \cite{Sohn2013} được xây dựng dựa trên cTakes và được cung cấp bởi hội đồng Open Health Natural Language Processing hỗ trợ cho quá trình rút trích đặc trưng.

MedEx là công cụ hỗ trợ trích xuất các thông tin ngữ nghĩa về thuốc y tế từ các văn bản thuần không có cấu trúc. Trong bệnh án điện tử, các thông tin về thuốc, bao gồm tên thuốc và các chỉ dẫn về cách sử dụng, thường được lưu trữ dưới dạng những câu văn tường thuật. Ví dụ, hồ sơ xuất viện thường chứa những mô tả về các lần sử dụng thuốc của bệnh nhân trong quá trình điều trị, như câu \texttt{"The patient was upgraded to Prilosec 20 mg per day for possible treatment of gastritis"} chứa tên thuốc \texttt{"Prilosec"} với liều lượng là \texttt{"20 mg"} và sử dụng mỗi ngày (\texttt{"per day"}). Các thông tin về thuốc là những thông tin quan trọng để phân giải đồng tham chiếu, vì vậy chúng tôi sử dụng MedEx để hỗ trợ cho việc rút trích các đặc trưng liên quan đến chúng. Bảng \ref{tab:med-info} trình bày các thông tin thuốc mà MedEx hỗ trợ trích xuất. Hình \ref{medex-eg} mô tả một tập tin được xuất ra bởi MedEx.
%
%\noindent trong đó thông tin về thuốc bao gồm:
%
%\begin{itemize}
%\item Tên thuốc (Drug name) như kháng sinh, Vancomycin , ...
%\item Nhà sản xuất (Brand name) như Zocor, ...
%\item Dạng thuốc (Drug form) như dạng viên nén, dạng viên nhộng, ...
%\item Mức độ (Strength) như 10mg, 5ml, ...
%\item Liều lượng (Dose amount) như 2 viên, ...
%\item Đường hấp thụ (Route) như qua đường miệng, qua đường tiêm, ...
%\item Tần số (Frequency) như 2 lần mỗi ngày, mỗi sáng, ...
%\item Thời gian (Duration) như trong 10 ngày, trong 1 tháng, ...
%\end{itemize}

\begin{table}[ht]
\centering\ra{1.2}
\caption{Các loại thông tin thuốc được trích xuất bởi MedEx\label{tab:med-info}}
\footnotesize\sffamily

\begin{tabularx}{0.8\textwidth}{@{}XX@{}}
\toprule
\textbf{Thông tin} & \textbf{Ví dụ}\\
\midrule
Tên thuốc (drug name) & `Lisinopril', `Famotidine'\\
Dạng thuốc (form) & `tablet', `ointment'\\
Mức độ (strength) & `50 mg', `500/50'\\
Liều lượng (dosage) & `take one tablet'\\
Đường hấp thụ (route) & `by mouth', `intravenous'\\
Tần số (frequency) & `2 times a day', `each morning',...\\
Thời gian sử dụng (duration) & `for 10 days', `in a month',...\\
\bottomrule
\end{tabularx}
\end{table}

MedTime là công cụ hỗ trợ trích xuất các thông tin về thời gian trong văn bản thuần không có cấu trúc, bao gồm hai loại là thời gian tường minh và thời gian suy diễn. Thời gian tường minh là các dạng thời gian được ghi một cách cụ thể trong văn bản bao gồm ngày, tháng, năm và có hoặc không có thời điểm, ví dụ như 03/06/2015. Thời gian suy diễn là các mốc thời gian được trích xuất từ một số từ khóa đứng gần khái niệm đang xét hoặc các khái niệm chỉ về sự kiện trong y tế, ví dụ như \emph{ngày nhập viện} (admission date) hay \emph{ngày thứ 2 sau khi phẫu thuật} (post-op day 2). Giống như công cụ MedEx, MedTime nhận đầu vào là các văn bản thuần không có cấu trúc và xuất ra kết quả là một tập tin chứa các thông tin thời gian được nhận dạng (Hình \ref{medtime-eg}).

\begin{figure}[ht]
\centering
\lstset{
	language=xml,
	keywords={},
	tabsize=3,
	%frame=lines,
	frame=single,
	xleftmargin=20pt,
	framexleftmargin=15pt,
	numbers=left,
	numberstyle=\tiny,
	numbersep=5pt,
	breaklines=true,
	showstringspaces=false,
	columns=fullflexible,
	basicstyle=\footnotesize\ttfamily}
\lstinputlisting{sample_code/ctakes_desc.xml}
\caption{Ví dụ nội dung tập tin XML mô tả hệ thống con cTakes\label{ctakesdesc}}
\end{figure}
\begin{figure}[ht]
\centering
\lstset{
	keywords={},
	tabsize=3,
	%frame=lines,
	frame=single,
	xleftmargin=20pt,
	framexleftmargin=15pt,
	numbers=left,
	numberstyle=\tiny,
	numbersep=5pt,
	breaklines=true,
	showstringspaces=false,
	columns=fullflexible,
	basicstyle=\footnotesize\ttfamily}
\lstinputlisting{sample_code/medex_output.txt}
\caption{Ví dụ nội dung tập tin kết quả được xuất ra bởi MedEx\label{medex-eg}}
\end{figure}
\begin{figure}[h!]
\centering
\lstset{
	keywords={},
	tabsize=3,
	%frame=lines,
	frame=single,
	xleftmargin=20pt,
	framexleftmargin=15pt,
	numbers=left,
	numberstyle=\tiny,
	numbersep=5pt,
	breaklines=true,
	showstringspaces=false,
	columns=fullflexible,
	basicstyle=\footnotesize\ttfamily}
\lstinputlisting{sample_code/medtime_output.txt}
\caption{Ví dụ nội dung tập tin kết quả được xuất ra bởi MedTime\label{medtime-eg}}
\end{figure}
